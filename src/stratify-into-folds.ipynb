{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ade3e6d-0057-4756-a1bc-ae70b6bd853e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10351, 297598) (10351, 10)\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "name_to_id = dill.load(open(\"./../annotation/name_to_id.dill\",\"rb\"))\n",
    "id_to_name = dill.load(open(\"./../annotation/id_to_name.dill\",\"rb\"))\n",
    "\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import random\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data using pyarrow for faster reading\n",
    "file_path = './../data/GEO/preprocessed/training_Mvalues.parquet'\n",
    "table = pq.read_table(file_path)\n",
    "\n",
    "# Convert to pandas DataFrame if needed\n",
    "Mv = table.to_pandas().set_index('probe')\n",
    "Mv.columns = Mv.columns.str.split('_').str[0]\n",
    "meta = pd.read_csv('./../annotation/training_meta.csv', header=0, index_col='Sample')\n",
    "\n",
    "random.seed(9)\n",
    "groups = meta['Dataset'].unique()\n",
    "random.shuffle(groups)\n",
    "\n",
    "meta = meta.reset_index().rename(columns={'index':'Sample'}).set_index(\"Dataset\").loc[groups].reset_index().set_index(\"Sample\")\n",
    "Mv = Mv.T.loc[meta.index]\n",
    "\n",
    "print(Mv.shape, meta.shape)\n",
    "\n",
    "with open(f'./../data/GEO/preprocessed/training.dill', 'wb') as f:\n",
    "    dill.dump([Mv, meta], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f21f7d-47dd-49d4-8964-9d2139e37615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 297598) (6, 10)\n",
      "(4, 297598) (4, 10)\n",
      "(10, 297598) (10, 10)\n",
      "(42, 297598) (42, 10)\n"
     ]
    }
   ],
   "source": [
    "excretory_meta = meta[meta['training.ID'].isin(name_to_id['excretory system'])]\n",
    "excretory_Mv = Mv.loc[excretory_meta.index]\n",
    "print(excretory_Mv.shape, excretory_meta.shape)\n",
    "\n",
    "sensory_meta = meta[meta['training.ID'].isin(name_to_id['sensory system'])]\n",
    "sensory_Mv = Mv.loc[sensory_meta.index]\n",
    "print(sensory_Mv.shape, sensory_meta.shape)\n",
    "\n",
    "cardio_meta = meta[meta['training.ID'].isin(name_to_id['cardiovascular system'])]\n",
    "cardio_Mv = Mv.loc[cardio_meta.index]\n",
    "print(cardio_Mv.shape, cardio_meta.shape)\n",
    "\n",
    "nervous_meta = meta[meta['training.ID'].isin(name_to_id['nervous system'])]\n",
    "nervous_Mv = Mv.loc[nervous_meta.index]\n",
    "print(nervous_Mv.shape, nervous_meta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91fad63c-2fa3-4cb7-a068-7582d84092fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StratifiedGroupKFold(n_splits=3, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "Mv = Mv[~Mv.index.isin(excretory_Mv.index)]\n",
    "meta = meta[~meta.index.isin(excretory_meta.index)]\n",
    "\n",
    "Mv = Mv[~Mv.index.isin(sensory_Mv.index)]\n",
    "meta = meta[~meta.index.isin(sensory_meta.index)]\n",
    "\n",
    "# sgkf = StratifiedGroupKFold(n_splits=3, shuffle=True, random_state=9) # if shuffle=True, then some folds with no training for some labels\n",
    "sgkf = StratifiedGroupKFold(n_splits=3, shuffle=False, random_state=None)\n",
    "sgkf.get_n_splits(Mv, meta['training.ID'], meta['Dataset'])\n",
    "print(sgkf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec5de611-ad72-4014-9d2f-29ad891d76b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n",
      "\ttrain: len=6778, groups=140\n",
      "\tvalidation:  len=3563, groups=68\n",
      "\ttrain and validation shapes: ((6778, 297598), (3563, 297598))\n",
      "fold 1:\n",
      "\ttrain: len=6980, groups=143\n",
      "\tvalidation:  len=3361, groups=65\n",
      "\ttrain and validation shapes: ((6980, 297598), (3361, 297598))\n",
      "fold 2:\n",
      "\ttrain: len=6924, groups=133\n",
      "\tvalidation:  len=3417, groups=75\n",
      "\ttrain and validation shapes: ((6924, 297598), (3417, 297598))\n",
      "\n",
      "...print if any overlap GSE between training and validation...\n",
      "fold0: set()\n",
      "fold1: set()\n",
      "fold2: set()\n"
     ]
    }
   ],
   "source": [
    "fold_Mvs = dict()\n",
    "fold_selectors = dict()\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(sgkf.split(Mv, meta['training.ID'], meta['Dataset'])):\n",
    "    print(f\"fold {i}:\")\n",
    "    print(f\"\\ttrain: len={len(train_index)}, groups={len(meta['Dataset'][train_index].unique())}\")\n",
    "    print(f\"\\tvalidation:  len={len(test_index)}, groups={len(meta['Dataset'][test_index].unique())}\")\n",
    "    \n",
    "    rest_Mv = Mv.iloc[train_index]\n",
    "    rest_meta = meta.iloc[train_index]\n",
    "    holdout_Mv = Mv.iloc[test_index]\n",
    "    holdout_meta = meta.iloc[test_index]\n",
    "    \n",
    "    print(f\"\\ttrain and validation shapes: {rest_Mv.shape, holdout_Mv.shape}\")\n",
    "    \n",
    "    fold_Mvs[i] = [rest_Mv, rest_meta, holdout_Mv, holdout_meta]\n",
    "    \n",
    "print('\\n...print if any overlap GSE between training and validation...')\n",
    "for fold, fold_data in fold_Mvs.items():\n",
    "    print(f\"fold{fold}: {set(fold_data[1]['Dataset']).intersection(fold_data[3]['Dataset'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a81393-7645-44fa-8f06-b726b625cfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print cardio series distribution across folds, add excretory system to that with one\n",
      "fold0: training 2\n",
      "fold0: holdout 0\n",
      "fold1: training 1\n",
      "fold1: holdout 1\n",
      "fold2: training 1\n",
      "fold2: holdout 1\n"
     ]
    }
   ],
   "source": [
    "print('print cardio series distribution across folds, add excretory system to that with one')\n",
    "for fold, fold_data in fold_Mvs.items():\n",
    "    print(f\"fold{fold}: training {fold_data[1][fold_data[1]['training.ID'].isin(name_to_id['cardiovascular system'])]['Dataset'].nunique()}\")\n",
    "    print(f\"fold{fold}: holdout {fold_data[3][fold_data[3]['training.ID'].isin(name_to_id['cardiovascular system'])]['Dataset'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0700b6fa-751a-4a5c-9523-fc596079c131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print kidney series distribution across folds, add excretory system to that with one\n",
      "fold0 2\n",
      "fold0 2\n",
      "fold1 3\n",
      "fold1 1\n",
      "fold2 3\n",
      "fold2 1\n"
     ]
    }
   ],
   "source": [
    "print('print kidney series distribution across folds, add excretory system to that with one')\n",
    "for fold, fold_data in fold_Mvs.items():\n",
    "    print(f\"fold{fold} {fold_data[1][fold_data[1]['training.ID'].isin(name_to_id['kidney'])]['Dataset'].nunique()}\")\n",
    "    print(f\"fold{fold} {fold_data[3][fold_data[3]['training.ID'].isin(name_to_id['kidney'])]['Dataset'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22b5e8e0-286d-4c5f-8272-5d6ffeb21478",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_Mvs[0][0] = pd.concat([fold_Mvs[0][0], excretory_Mv])\n",
    "fold_Mvs[0][1] = pd.concat([fold_Mvs[0][1], excretory_meta])\n",
    "fold_Mvs[1][0] = pd.concat([fold_Mvs[1][0], excretory_Mv])\n",
    "fold_Mvs[1][1] = pd.concat([fold_Mvs[1][1], excretory_meta])\n",
    "fold_Mvs[2][2] = pd.concat([fold_Mvs[2][2], excretory_Mv])\n",
    "fold_Mvs[2][3] = pd.concat([fold_Mvs[2][3], excretory_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc716931-696a-4dd1-9b7e-74ecc11ae87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n",
      "\ttrain and validation shapes: ((6784, 297598), (3563, 297598))\n",
      "\ttotal number of samples in fold: 10347\n",
      "fold 1:\n",
      "\ttrain and validation shapes: ((6986, 297598), (3361, 297598))\n",
      "\ttotal number of samples in fold: 10347\n",
      "fold 2:\n",
      "\ttrain and validation shapes: ((6924, 297598), (3423, 297598))\n",
      "\ttotal number of samples in fold: 10347\n"
     ]
    }
   ],
   "source": [
    "for i, [rest_Mv, rest_meta, holdout_Mv, holdout_meta] in fold_Mvs.items():\n",
    "    print(f\"fold {i}:\")\n",
    "    print(f\"\\ttrain and validation shapes: {rest_Mv.shape, holdout_Mv.shape}\")\n",
    "    print(f\"\\ttotal number of samples in fold: {rest_Mv.shape[0]+holdout_Mv.shape[0]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46e8ed4b-0223-4ea9-9b85-6144ed35eab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "print nasal cavity epithelium series distribution across folds, add sensory system to that with one\n",
      "fold0: 2\n",
      "fold0: 2\n",
      "fold1: 3\n",
      "fold1: 1\n",
      "fold2: 3\n",
      "fold2: 1\n"
     ]
    }
   ],
   "source": [
    "print('print nasal cavity epithelium series distribution across folds, add sensory system to that with one')\n",
    "for fold, fold_data in fold_Mvs.items():\n",
    "    print(f\"fold{fold}: {fold_data[1][fold_data[1]['training.ID'].isin(name_to_id['nasal cavity epithelium'])]['Dataset'].nunique()}\")\n",
    "    print(f\"fold{fold}: {fold_data[3][fold_data[3]['training.ID'].isin(name_to_id['nasal cavity epithelium'])]['Dataset'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5b5f3a3-5b37-43df-9d80-8ed17a2b2870",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_Mvs[0][0] = pd.concat([fold_Mvs[0][0], sensory_Mv])\n",
    "fold_Mvs[0][1] = pd.concat([fold_Mvs[0][1], sensory_meta])\n",
    "fold_Mvs[1][0] = pd.concat([fold_Mvs[1][0], sensory_Mv])\n",
    "fold_Mvs[1][1] = pd.concat([fold_Mvs[1][1], sensory_meta])\n",
    "fold_Mvs[2][2] = pd.concat([fold_Mvs[2][2], sensory_Mv])\n",
    "fold_Mvs[2][3] = pd.concat([fold_Mvs[2][3], sensory_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1e6ceb28-8ba0-4204-87ab-4dd5b7cb1b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0:\n",
      "\ttrain and validation shapes: ((6788, 297598), (3563, 297598))\n",
      "\ttotal number of samples in fold: 10351\n",
      "fold 1:\n",
      "\ttrain and validation shapes: ((6990, 297598), (3361, 297598))\n",
      "\ttotal number of samples in fold: 10351\n",
      "fold 2:\n",
      "\ttrain and validation shapes: ((6924, 297598), (3427, 297598))\n",
      "\ttotal number of samples in fold: 10351\n"
     ]
    }
   ],
   "source": [
    "for i, [rest_Mv, rest_meta, holdout_Mv, holdout_meta] in fold_Mvs.items():\n",
    "    print(f\"fold {i}:\")\n",
    "    print(f\"\\ttrain and validation shapes: {rest_Mv.shape, holdout_Mv.shape}\")\n",
    "    print(f\"\\ttotal number of samples in fold: {rest_Mv.shape[0]+holdout_Mv.shape[0]}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25e08ab8-c548-4752-9216-fbe8e139462d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of holdout: 10351\n",
      "duplicates?: Empty DataFrame\n",
      "Columns: [Dataset, Unnamed: 0, Annotated.tissue, UBERON.ID, UBERON.Name, Display.Name, merged.ID, training.ID, File, FileSeries]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "all_holdout = pd.concat([fold_Mvs[0][3], fold_Mvs[1][3], fold_Mvs[2][3]])\n",
    "print(f\"total number of holdout: {all_holdout.shape[0]}\")\n",
    "print(f\"duplicates?: {all_holdout[all_holdout.index.duplicated()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "465cc791-fbcb-4092-8ae3-a25863d0c6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./../data/GEO/preprocessed/training_folds.dill', 'wb') as f:\n",
    "    dill.dump(fold_Mvs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd48f80-4163-4580-a483-2da718a1a282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "methyl",
   "language": "python",
   "name": "methyl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
